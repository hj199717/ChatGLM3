from transformers import AutoTokenizer, AutoModel
import gradio as gr
import os
from prompts_tests import extract_and_concatenate_values, extract_user_data, extract_quotes_content
from user_matching import *
import re

# from retrieval_test import langtrainembeding

# test=langtrainembeding()
path = "kgs3.json"


# tokenizer = AutoTokenizer.from_pretrained("/home/LLM/chatglm3-6b/", trust_remote_code=True)
# model = AutoModel.from_pretrained("/home/LLM/chatglm3-6b/", trust_remote_code=True).half().cuda()
#
# model = model.eval()


def add_text(history, text):
    history = history + [(text, None)]
    print("---------", history, gr.update(value="", interactive=False))
    return history, gr.update(value="", interactive=False)


def bot(history):
    """
    èŠå¤©è°ƒç”¨çš„å‡½æ•°
    :param history:
    :return:
    """
    message = history[-1][0]
    print(history)

    if isinstance(message, tuple):
        response = "æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼ï¼"
    else:
        text = history[-1][0]
        print("==============================", text)
        user = extract_quotes_content(text)[0]
        print(user)
        kg_one, kg_attr = extract_user_data(path, user)

        kg_one = re.sub(r'\\', '', str(kg_one))
        kg_location = extract_and_concatenate_values(str(kg_one), 'åœ°ç†ä½ç½®')
        kg_content = extract_and_concatenate_values(str(kg_one), 'å‘æ–‡å†…å®¹')
        kg_emotion = extract_and_concatenate_values(str(kg_one), 'å‘æ–‡å€¾å‘æ€§')
        kg_aite = extract_and_concatenate_values(str(kg_one), 'æåŠå¥½å‹')
        #
        text_attr = """è¯·æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å®Œæˆå›ç­”ï¼Œå›ç­”å†…å®¹å¿…é¡»ä¸¥æ ¼éµå®ˆçŸ¥è¯†çº¦æŸ:{}ï¼Œå›ç­”é—®é¢˜ï¼šè¯·è¾“å‡ºæ–‡æœ¬{}ä¸­çš„å¯¹åº”å­—æ®µï¼Œä½œä¸ºç”¨æˆ·çš„åŸºæœ¬å±æ€§ä¿¡æ¯""".format(
            kg_attr, kg_attr)
        text_id = """è¯·æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å®Œæˆå›ç­”ï¼Œå›ç­”å†…å®¹å¿…é¡»ä¸¥æ ¼éµå®ˆçŸ¥è¯†çº¦æŸ:{}ï¼Œå›ç­”é—®é¢˜ï¼šè¯·è®¡ç®—æ–‡æœ¬{}ä¸­ï¼Œ'ç”¨æˆ·id'å‡ºç°çš„æ¬¡æ•°ï¼Œåªéœ€è¦å›ç­”ä¸€ä¸ªæ•°å€¼å¤§å°å³å¯ï¼Œä¸éœ€è¦å…¶ä»–å†…å®¹""".format(
            kg_one, kg_one)
        text_location = """è¯·æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å®Œæˆå›ç­”ï¼Œå›ç­”å†…å®¹å¿…é¡»ä¸¥æ ¼éµå®ˆçŸ¥è¯†çº¦æŸ:{}ï¼Œå›ç­”é—®é¢˜ï¼šè¯·è®¡ç®—æ–‡æœ¬{}ä¸­ï¼Œ'ç”¨æˆ·id'å‡ºç°çš„æ¬¡æ•°ï¼Œåªéœ€è¦å›ç­”ä¸€ä¸ªæ•°å€¼å¤§å°å³å¯ï¼Œä¸éœ€è¦å…¶ä»–å†…å®¹""".format(
            kg_location, kg_location)
        text_content = """è¯·æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å®Œæˆå›ç­”ï¼Œå›ç­”å†…å®¹å¿…é¡»ä¸¥æ ¼éµå®ˆçŸ¥è¯†çº¦æŸ:{},å›ç­”é—®é¢˜ï¼šè¯·æ¦‚æ‹¬ä¸€ä¸‹{}çš„å…³é”®è¯ï¼Œè¾“å‡ºæœ€å…·ä»£è¡¨æ€§çš„3ä¸ªå…³é”®è¯""".format(
            kg_content, kg_content)
        text_emotion = """è¯·æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å®Œæˆå›ç­”ï¼Œå›ç­”å†…å®¹å¿…é¡»ä¸¥æ ¼éµå®ˆçŸ¥è¯†çº¦æŸ:{}ï¼Œå›ç­”é—®é¢˜ï¼šè¯·é—®{}ä¸­çš„å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿï¼Œä¸éœ€è¦å…¶ä»–å†…å®¹""".format(
            kg_emotion, kg_emotion)
        text_aite = """è¯·æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å®Œæˆå›ç­”ï¼Œå›ç­”å†…å®¹å¿…é¡»ä¸¥æ ¼éµå®ˆçŸ¥è¯†çº¦æŸ:{}ï¼Œå›ç­”é—®é¢˜ï¼šè¯·é—®{}ä¸­çš„å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ""".format(
            kg_aite, kg_aite)

        #
        response_id = model.chat(tokenizer, text_id, history=[])[0]
        response_location = model.chat(tokenizer, text_location, history=[])[0]
        response_content = model.chat(tokenizer, text_content, history=[])[0]
        response_emotion = model.chat(tokenizer, text_emotion, history=[])[0]
        response_aite = model.chat(tokenizer, text_aite, history=[])[0]

        texts = """è¯·ä¸»è¦å‚è€ƒæä¾›ä»¥ä¸‹çŸ¥è¯†å®Œæˆå›ç­”ï¼Œå›ç­”å†…å®¹å¿…é¡»ä¸¥æ ¼éµå®ˆçŸ¥è¯†çº¦æŸï¼šä»¥ä¸‹æ˜¯ç”¨æˆ·"{}"çš„å±æ€§ä¿¡æ¯{}ï¼Œè¿‘æœŸçš„å¾®åšè¡Œä¸ºæ•°æ®:"ç”¨æˆ·åœ°ç†ä½ç½®ï¼š{}ï¼Œç”¨æˆ·å‘æ–‡æ¬¡æ•°ï¼š{},å‘æ–‡å…³é”®è¯ï¼š{},å‘æ–‡å€¾å‘æ€§ä¸ºï¼š{}ï¼ŒæåŠå¥½å‹ä¸ºï¼š{}"ï¼Œè¯·æ ¹æ®ä¸Šè¿°çŸ¥è¯†ï¼Œå›ç­”é—®é¢˜ï¼š{}ï¼Œ
        åªéœ€è¦è¾“å‡ºç”¨æˆ·æ€§åˆ«ï¼Œç”¨æˆ·ç­‰çº§ï¼Œç²‰ä¸æ•°ï¼Œå…³æ³¨æ•°ï¼Œäº’å…³æ•°ï¼Œåˆ›å»ºæ—¶é—´ï¼Œæ˜¯å¦è®¤è¯ï¼Œè®¤è¯ç±»å‹ï¼Œç”¨æˆ·åœ°ç†ä½ç½®ï¼Œç”¨æˆ·å‘æ–‡æ¬¡æ•°ï¼Œå‘æ–‡å…³é”®è¯ï¼Œå‘æ–‡å€¾å‘ï¼ŒæåŠå¥½å‹æ˜¯è°å³å¯ï¼Œå¦‚æœæ²¡æœ‰ï¼Œç›´æ¥å›ç­”æ— å³å¯ã€‚å¹¶åŸºäºä¸Šè¿°ä¿¡æ¯ï¼Œç»“åˆæ”¿æ²»æ–¹é¢ï¼Œå¯¹ç”¨æˆ·è¿›è¡Œæ·±å±‚æ¬¡åˆ†æ""".format(
            user, text_attr, response_location, response_id, response_content, response_emotion, response_aite, text)

        history[-1][1] = model.chat(tokenizer, texts, history=[])[0]

    yield history


# with gr.Blocks(css=".gradio-interface {height: 1400px;") as demo:
#
#     with gr.Row(variant="panel",elem_classes=".gradio-interface {height: 1400px;"):
#
#         introduction = gr.Textbox(lines=10, label="SongshanLab", default_value="nihao")
#
#         with gr.Column(scale=4):
#             # chatbot = gr.Chatbot(label='SongshanLab',height=1000,bubble_full_width=False)
#             chatbot = gr.Chatbot(
#
#                 [],
#                 title="SongshanLab",
#                 # height=1000,
#                 bubble_full_width=False,
#                 avatar_images=(None, (os.path.join(os.path.dirname(__file__), "avatar.png"))),
#                 )
#             with gr.Row():
#                 txt = gr.Textbox(
#                     scale=10,
#                     show_label=False,
#                     placeholder="Enter text and press enter, or upload an image",
#                     container=False,
#                 )
#                 btn = gr.UploadButton("ğŸ“", file_types=['txt'])
#
#     txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(
#         bot, chatbot, chatbot
#     )
#
#     txt_msg.then(lambda: gr.update(interactive=True), None, [txt], queue=False)
def process_csv(file):
    # ä½¿ç”¨ Pandas è¯»å–ä¸Šä¼ çš„ CSV æ–‡ä»¶å¹¶è½¬æ¢ä¸º DataFrame
    df = pd.read_csv(file.name)
    # è¿”å› DataFrame
    return df


with gr.Blocks(css=".gradio-interface {height: 1400px;") as demo:
    gr.Markdown("<center><strong> <font color=grey size=5> åµ©å±±å®éªŒå®¤ç”¨æˆ·ç”»åƒå¤§æ¨¡å‹ç³»ç»Ÿ </font><strong> </center>")
    with gr.TabItem("ç”¨æˆ·ç”»åƒç³»ç»Ÿ"):
        with gr.Row():
            with gr.Column():
                # radio = gr.Radio(
                # ["ç”¨æˆ·ç”»åƒåŠŸèƒ½", "ç”¨æˆ·ç”»åƒå®šåˆ¶åŠŸèƒ½"], label="è¯·é€‰æ‹©åŠŸèƒ½")
                img = gr.Image("songshanlogo.png", label='logo', height=200)
                text = gr.Textbox(lines=4, label="ç”¨æˆ·ç”»åƒç³»ç»Ÿä»‹ç»", interactive=True,
                                  value="å®šåˆ¶ç”¨æˆ·ç”»åƒåŠŸèƒ½ï¼Œå¯ä»¥æ ¹æ®ç”¨æˆ·çš„éœ€æ±‚ï¼Œç»“åˆçŸ¥è¯†åº“ä¸­çš„æ•°æ®ï¼Œå¯¹ç”¨æˆ·ç”»åƒè¿›è¡Œé¢„æµ‹ã€‚")
                # radio.change(fn=change_textbox, inputs=radio, outputs=text)
                bar = gr.Slider(label='å¤§æ¨¡å‹æ¸©åº¦', value=0.1, minimum=0, maximum=1, step=0.05, container=True,
                                interactive=True)
                models = gr.Dropdown(label='å¤§æ¨¡å‹é€‰æ‹©', value='gemma:7b-instruct-fp16', allow_custom_value=True,
                                     choices=['gemma:7b-instruct-fp16',
                                              # 'gemma:7b-text-fp16',
                                              'gemma:7b']
                                     , interactive=True)
                changess = gr.CheckboxGroup(
                    ["æ°´å†›å€¾å‘", "è¾±éª‚å€¾å‘", "ä¿¡è®¿å€¾å‘", "è¯ˆéª—å€¾å‘", "è¿½æ˜Ÿå€¾å‘", "è´­ç‰©å€¾å‘", "æ”¿åŠ¡å€¾å‘", "ç½‘æš´å€¾å‘"],
                    label="ç”¨æˆ·ç”»åƒå®šåˆ¶", info="å¯ä»¥é€‰æ‹©æŒ‰é’®ï¼Œå®šåˆ¶ç”¨æˆ·ç”»åƒé¢„æµ‹")
            with gr.Column(scale=8):
                chatbot = gr.Chatbot(label='SongshanLab', height=700, bubble_full_width=False,
                                     avatar_images=(None, (os.path.join(os.path.dirname(__file__), "avatar.png"))), )
                with gr.Row():
                    txt = gr.Textbox(
                        scale=10,
                        show_label=False,
                        placeholder="è¯·è¾“å…¥ç”¨æˆ·æ˜µç§°è¿›è¡Œç”¨æˆ·ç”»åƒé¢„æµ‹...",
                        container=False,
                    )
                    btn = gr.UploadButton("ğŸ“", file_types=['txt'])
                    user_csv = gr.DataFrame(visible=False)
                    btn.click(process_csv, [btn], )

        # text_button.click(flip_text, inputs=text_input, outputs=text_output)

        txt_msg = txt.submit(add_text, [chatbot, txt, changess], [chatbot, txt], queue=False).then(
            bot, chatbot, chatbot)

        txt_msg.then(lambda: gr.update(interactive=True), None, [txt], queue=False)

    with gr.TabItem("ç”¨æˆ·åŒ¹é…ç³»ç»Ÿ"):
        # print(gr.__version__)
        with gr.Row():
            with gr.Column(scale=1, min_width=200):
                img = gr.Image("songshanlogo.png", label='logo', height=200)
                use_pattern = gr.Radio([
                    'è·¨ç½‘åŸŸåŒ¹é…',
                    'è·¨å¹³å°åŒ¹é…',
                    'åŒå¹³å°åŒ¹é…'],
                    label="åŒ¹é…æ¨¡å‹åˆ†ææ¨¡å¼",
                    value='åŒå¹³å°åŒ¹é…',
                    interactive=True,
                    container=True,
                    # scale=1
                )
                # inter = gr.Interface(
                #     illustrate_pattern,
                #     inputs=[use_pattern],
                #     outputs=[gr.Textbox(label="åŒ¹é…æ¨¡å‹ä½¿ç”¨è¯´æ˜:",lines=2,value="åŒå¹³å°åŒ¹é…")],
                #     live=True,
                #     allow_flagging="never"
                # )
                plat1 = gr.Dropdown(label='å¹³å°1ï¼ˆåŸå§‹å¹³å°ï¼‰', value='å¾®åš', allow_custom_value=False,
                                    choices=['å¾®åš', 'ä»Šæ—¥å¤´æ¡', 'æŠ–éŸ³', 'Bç«™', 'ç”µä¿¡ç½‘'])
                plat2 = gr.Dropdown(label='å¹³å°2ï¼ˆåŒ¹é…å¹³å°ï¼‰', value='å¾®åš', allow_custom_value=False,
                                    choices=['å¾®åš', 'ä»Šæ—¥å¤´æ¡', 'æŠ–éŸ³', 'Bç«™', 'ç”µä¿¡ç½‘'])
                use_pattern.change(mode_change, use_pattern, [plat1, plat2])

                temperature = gr.Slider(label='å¤§æ¨¡å‹æ¸©åº¦', value=0, minimum=0, maximum=1, step=0.05, container=True)
                top_p = gr.Slider(label='å¤§æ¨¡å‹top_p', value=0, minimum=0, maximum=1, step=0.05, container=True)
                model = gr.Dropdown(label='å¤§æ¨¡å‹é€‰æ‹©', value='gemma:7b-instruct-fp16', allow_custom_value=True,
                                    choices=['gemma:7b-instruct-fp16',
                                             # 'gemma:7b-text-fp16',
                                             'qwen:72b',
                                             'ChatGLM3-6B',
                                             'gemma:7b'])
            with gr.Column(scale=8):
                with gr.Group():
                    with gr.Row():
                        # user_name=gr.Textbox(label="å¾…åŒ¹é…ç”¨æˆ·å",value='è€æ¨ysh_73')
                        user_name = gr.Dropdown(label="å¾…åŒ¹é…ç”¨æˆ·åï¼ˆå¾®åšï¼‰å¹³å°",
                                                # value='è€æ¨ysh_73',
                                                allow_custom_value=True,
                                                choices=['è€æ¨ysh_73', 'znlæå…ˆç”Ÿ', 'SOD_å¤§å®', 'å†·æ¸©æŸ”Triste998',
                                                         'ç¦…æ˜¯ç¦…é', 'Biggå®‡å®™', 'é™ˆæ›¦guitar',
                                                         'é©¬ä¸½lili', 'å¤©ç¿¼å¸å·11018428363', 'Gå‹116987631',
                                                         'ç‚«é“ƒç”¨æˆ·2911236035', 'å¤šç±³éŸ³ä¹_8196567',
                                                         'é¹¤å£vivoXpiay', 'è´å£³æ‰‹æœºç”¨æˆ·2925697', 'å‚²é›ªå¯’æ¢…1213',
                                                         'ç‹æ³½Happy', 'å¤•é˜³beautiful'])

                        match_button = gr.Button("è¿›è¡ŒåŒ¹é…")
                        # match_name = gr.Textbox(label="åŒ¹é…æˆåŠŸçš„ç”¨æˆ·å")
                        match_name = gr.Dropdown(label="åŒ¹é…æˆåŠŸçš„ç”¨æˆ·åï¼ˆå¾®åšï¼‰å¹³å°", interactive=True,
                                                 allow_custom_value=False)

                        llm_button = gr.Button("æŸ¥çœ‹è¯¦ç»†åˆ†ææŠ¥å‘Š")

                    with gr.Row():
                        with gr.Accordion('æŸ¥çœ‹ç”¨æˆ·è¯¦ç»†èµ„æ–™', open=False):
                            user_detail = gr.DataFrame()  # label='ç”¨æˆ·èµ„æ–™')
                        with gr.Accordion('æŸ¥çœ‹åŒ¹é…ç”¨æˆ·è¯¦ç»†èµ„æ–™', open=False):
                            match_user_detail = gr.DataFrame()  # label='åŒ¹é…ç”¨æˆ·èµ„æ–™')
                match_button.click(find_match_user_list, [user_name, plat2], [match_name])
                llm_res = gr.Chatbot(label="ç”¨æˆ·åŒ¹é…åˆ†ææŠ¥å‘Š", height=650)
                llm_button.click(detailed_report, [model, temperature, top_p, user_name, match_name, plat1, plat2],
                                 [llm_res])
                user_name.change(find_user_pd, [user_name, plat1], user_detail)
                match_name.change(find_user_pd, [match_name, plat2], match_user_detail)
                # llm_res.postprocess('123')
                plat1.change(plat_change1, [use_pattern, plat1, plat2], [plat2, user_name])
                plat2.change(plat_change2, [use_pattern, plat1, plat2], [user_name, match_name])

                # chatbot = gr.Chatbot(label='SongshanLab', height=450, bubble_full_width=False)
                # message = gr.Textbox(label='è¯·è¾“å…¥é—®é¢˜: ')
                # clear_history = gr.Button("æ¸…é™¤")
                # send = gr.Button("å‘é€")

demo.queue()
if __name__ == "__main__":
    demo.launch(server_name='0.0.0.0', server_port=7860)
